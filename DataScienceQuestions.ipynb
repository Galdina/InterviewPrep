{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. What is Data Science?\n",
    "\n",
    "*The ability to take data to be able to understand it, to process it, to extract value from it, to visualize it, to communicate it - that is going to be a hugely important skill in the next decade.*\n",
    "\n",
    "## What is Data Science?\n",
    "\n",
    "Data Science can be defined as the field of deriving insights and value from data by solving problems in a scientific way. In order to derive insights, data science utilizes tools and concepts from several fields: statistics, data engineering, computer science, and machine learning.\n",
    "\n",
    "As a field, data science was only established recently. But the process of deriving insights and value from data has been around for while; quants have been deriving trading signals from data for decades, actuaries have been assessing risk from data for insurance and finance companies for decades, economists have been applying econometric methods to data for decades. So why the sudden increase in \"data science\" activity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are few main factors:\n",
    "1. <u>Explosion of Data:</u> new technology has allowed us to collect data from billions of devices all over the world, every second of the day, and store it cheaply. We now have several zetabytes of data and now we can start to think about what insights can be uncovered.\n",
    "2. <u>Technological Advances:</u>  computing advances like MapREduce zallow us to process vast amounts of data, technological advances like cloud computing provide easy access to vast amounts of computing power on demand, and hardware advances like GPUs makes it feasible for certain machine learning algorithms to work faster and more efficiently.\n",
    "3. <u>Success Stories:</u>  there have been many success stories about leveraging data science in various fields, from quantitative investing to election/sports forecasting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Solution to Big Ideas in Data Science.\n",
    "##\n",
    " 1. Explain what regularization is and why it is useful?\n",
    " \n",
    "Regularization is the process of adding a penalty to the cost function of a model to shrink the coefficient estimates. It is usefull because it helps prevent overfitting. The most common forms are L1 (Lasso) and L2 (Ridge). One advantage of Lasso is that it can force coefficients to be zero and act as a feature selector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions from interviews\n",
    "\n",
    "**This problem was asked by Facebook.**\n",
    "\n",
    "There is a fair coin (one side heads, one side tails) and an unfair coin (both sides tails). You pick one at random, flip it 5 times, and observe that it comes up as tails all five times. What is the chance that you are flipping the unfair coin?\n",
    "\n",
    "We can use Bayes Theorem here. Let U denote the case where we are flipping the unfair coin and F denote the case where we are flipping a fair coin. Since the coin is chosen randomly, we know that P(U) = P(F) = 0.5. Let 5T denote the event where we flip 5 tails in a row. Then we are interested in solving for P(U|5T), i.e., the probability that we are flipping the unfair coin, given that we saw 5 tails in a row.\n",
    "\n",
    "We know P(5T|U) = 1 since by definition the unfair coin will always result in tails. Additionally, we know that P(5T|F) = 1/2^5 = 1/32 by definition of a fair coin. By Bayes Theorem we have:\n",
    "\n",
    "P(U|5T) = \\frac {P(5T|U) * P(U)}{P(5T|U) * P(U) + P(5T|F) * P(F)} = \\frac{0.5}{0.5 + 0.5 * 1/32} = 0.97\n",
    "P(U∣5T)= \n",
    "P(5T∣U)∗P(U)+P(5T∣F)∗P(F)\n",
    "P(5T∣U)∗P(U)\n",
    "​\t\n",
    " = \n",
    "0.5+0.5∗1/32\n",
    "0.5\n",
    "​\t\n",
    " =0.97\n",
    "Therefore the probability we picked the unfair coin is about 97%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_u = 0.5\n",
    "p_f = 0.5\n",
    "p_u_5T = 0.5/(0.5+0.5*(1/32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696969696969697"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_u_5T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This problem was asked by Google.**\n",
    "\n",
    "Say we have X ~ Uniform(0, 1) and Y ~ Uniform(0, 1). What is the expected value of the minimum of X and Y?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let Z = min(X, Y). Then we know:\n",
    "\n",
    "P(Z \\le z) = P(\\min(X, Y) \\le z) = 1 - P(X > z, Y > z)\n",
    "P(Z≤z)=P(min(X,Y)≤z)=1−P(X>z,Y>z)\n",
    "For a uniform distribution the following is true for a value of z between 0 and 1:\n",
    "\n",
    "P(X > z) = 1-z \\space \\text{and} \\space P(Y>z) = 1 - z\n",
    "P(X>z)=1−z and P(Y>z)=1−z\n",
    "Since X and Y are iid, this yields:\n",
    "\n",
    "P(Z \\le z) = 1 - P(X > z, Y > z) = 1 - (1-z)^2\n",
    "P(Z≤z)=1−P(X>z,Y>z)=1−(1−z) \n",
    "2\n",
    " \n",
    "Now we have the CDF of z. We can get the PDF by taking a derivative to get:\n",
    "\n",
    "f_Z(z)= 2(1-z)\n",
    "f \n",
    "Z\n",
    "​\t\n",
    " (z)=2(1−z)\n",
    "Then we can solve for the expected value by taking the integral:\n",
    "\n",
    "E[Z] = \\int_{0}^{1} zf_Z(z)dz = 2\\int_{0}^{1} z(1-z)dz = 2(\\frac{1}{2}-\\frac{1}{3}) = \\frac{1}{3}\n",
    "E[Z]=∫ \n",
    "0\n",
    "1\n",
    "​\t\n",
    " zf \n",
    "Z\n",
    "​\t\n",
    " (z)dz=2∫ \n",
    "0\n",
    "1\n",
    "​\t\n",
    " z(1−z)dz=2( \n",
    "2\n",
    "1\n",
    "​\t\n",
    " − \n",
    "3\n",
    "1\n",
    "​\t\n",
    " )= \n",
    "3\n",
    "1\n",
    "​\t\n",
    " \n",
    "Therefore the expected value for the minimum of X and Y is 1/3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This problem was asked by Uber.**\n",
    "\n",
    "You’re on the data science team and are responsible for figuring out surge pricing. Why does it need to exist and what metrics and data should you track?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surge pricing is a phenomenon because of supply and demand imbalance - either there may be a lack of drivers, or excess riders. Therefore, surge pricing exists to a) entice more drivers to use the app, and b) reduce demand by increasing prices for riders. Managing supply and demand is bottom-line critical to Uber’s business, so surge pricing needs to exist.\n",
    "\n",
    "Possible metrics to track (there are many) could be things including: number of active drivers, number of requested rides, pricing during rides, etc. - figuring out both the supply curve and demand curve is important to measure price elasticity, which there should ultimately be a model for. It is quite likely that price elasticities vary by city, type of ride, etc. so it would be important to track all of that data on a ride by ride basis when making surge pricing algorithms.\n",
    "\n",
    "Once enough data is there to do some basic modeling on price elasticities, we can do some A/B testing to look into the specific features on surge pricing that would make it useful to both riders and drivers, and measure the lift in both user and drive engagement, and overall revenue generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This problem was asked by Facebook.**\n",
    "\n",
    "Assume you have the below events table on app analytics. Write a query to get the click-through rate per app in 2019.\n",
    "\n",
    "|events| \n",
    "\n",
    "|column_name|\ttype|\\\n",
    "|app_id|\tinteger|\\\n",
    "|event_id|\tstring (\"impression\", \"click\")|\\\n",
    "|timestamp|\tdatetime|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the click-through rate, we can calculate the total sum of clicks and the total number of impressions, and then divide the two. The CASE statement comes in handy here, so we can use the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql =\"\"\"SELECT app_id,\n",
    "    SUM(CASE WHEN event_id = ‘click’ THEN 1 ELSE 0 END) /\n",
    "    SUM(CASE WHEN event_id = ‘impression’ THEN 1 ELSE 0 END) AS ctr\n",
    "FROM events\n",
    "    WHERE timestamp >= ‘2019-01-01’\n",
    "GROUP BY 1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
